## 处理流程

### 第一步：音频预处理
用户将待识别的音频文件通过post请求上传至服务端，并进行音频预处理，包括音频格式转换、通道选取、时长选取、重采样至8k、以及VAD操作提取有效音频。如果有效音时长小于阈值，则停止处理。

### 第二步：语种检测
经过音频预处理后，从有效音频中对语种进行分类，如果检出结果不是中文普通话（置信度>70%）则停止处理。

### 第三步：声纹提取与比对
满足语种检测要求后，对有效音频进行多模型声纹特征提取。将各模型特征与该模型对应的声纹黑库进行比对，得到各模型的比对结果。

#### 3.1 多模型结果融合

- 多模型评分与平均值获得`final_score`
- 如果`final_score`大于阈值，且**<u>所有top1的黑库ID相同</u>**，则认为该音频为该黑库的声纹，否则认为该说话人不存在于黑库中。

### 第四步：语音识别
对于认为存在于声纹黑库中的说话人，将其预处理后音频送至语音识别后端进行语音识别。

### 第五步：语义判别
将语音识别的结果送至语义判别后端进行语义判别，输出该文本涉诈骗类别及可疑程度(可疑程度分为,-1,0,1,2,3等级，越高代表越可疑)，得到最终结果。

### 第六步：结果导出与可视化
将各模块的处理结果进行导出与可视化，包括结果的导出和可视化等操作。

导出逻辑:

1.  对所有命中结果(hit表中所有记录)进行排序（一级：可疑程度，二级：最终评分，三级：质量检测得分，四级：音频有效时长）
2.  对排序后的命中结果取top-20获得结果A
3.  直接取评分最高的前20条记录获得结果B
4. 取结果A及结果B的并集，并进行排序（一级：可疑程度，二级：最终评分，三级：质量检测得分，四级：音频有效时长）得到最终结果。

```mermaid
graph TD;
    A[音频文件] --> B(音频预处理);
    B --> C{语种检测};
    C -- 中文普通话 --> D(声纹提取);
    D --> E(声纹比对);
    E --> F{多模型融合};
    F -- 同一黑库ID且final_score > 阈值 --> G(存在于声纹库中);
    G --> H(语音识别);
    H --> I(语义判别);
    I --> J(结果导出与可视化);
    C -- 非中文普通话 --> K(终止处理);
    F -- 不满足条件 --> K(终止处理);
    J -->L(所有命中结果排序);
    J -->M(取评分top-20命中结果A);
    L -->N(取话术可疑top-20结果B);
    M -->O(A-B 取交集输出)
    N -->O

```